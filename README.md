Bike Sharing Demand Prediction
This repository contains the code, datasets, and submission files for the Kaggle Bike Sharing Demand competition. The goal is to predict hourly bike rental counts (sum of casual and registered users) based on historical and contextual features, with performance evaluated using the Root Mean Squared Logarithmic Error (RMSLE).
Project Overview
The project develops a regression model to predict bike rental demand using the provided Kaggle dataset. Key steps include data preprocessing, feature engineering, model training, hyperparameter tuning, and visualization of predictions. The best model, a CatBoost with RandomizedSearchCV, achieved an RMSLE of 0.36312. Since the competition ended three years ago, new submissions are not reflected on the leaderboard. However, this RMSLE score would place the model between the 16th and 17th positions, effectively ranking 17th among historical competitors.
Repository Structure
The repository is organized into three main folders:

models/: Contains Python scripts (.py files) for all trained machine learning models.
submissions/: Contains CSV files with predictions generated by each model for the Kaggle test set.
datasets/: Contains the original and processed datasets used for training and testing.

Folder Details
models/
This folder includes Python scripts for each model trained during the project. Each script implements data preprocessing, feature engineering, model training, and prediction generation. The models include:

Linear Regression (RMSLE: 1.342)
Random Forest (RMSLE: 0.4790)
Random Forest with Log Target and GridSearch (RMSLE: 0.40447)
XGBoost with GridSearchCV (RMSLE: 0.38672)
XGBoost with RandomizedSearchCV (RMSLE: 0.37976)
LightGBM with Default Parameters (RMSLE: 0.37662)
LightGBM with RandomizedSearchCV (RMSLE: 0.37417)
CatBoost with Default Parameters (RMSLE: 0.36502)
CatBoost with RandomizedSearchCV (RMSLE: 0.36312, best)

File Naming: Each script is named according to the model and configuration (e.g., catboost_randomsearch.py).
submissions/
This folder contains CSV files with predictions for the Kaggle test set, formatted as required (columns: datetime, count). Each file corresponds to a model in the models/ folder.

Example: submission_catboost_randomsearch.csv contains predictions from the best-performing CatBoost model.
Note: The submission files include the final predictions after applying the inverse log transformation (np.expm1) to convert log-transformed predictions back to the original scale.

datasets/
This folder contains the original Kaggle datasets and any processed versions used during the project:

train.csv: The training dataset with features (e.g., datetime, season, temp, count) for model training.
test.csv: The test dataset for generating predictions, lacking the count column.
Processed Datasets: Any modified datasets (e.g., with added features like temp_lag1 or temp_squared) are stored here.

Dataset Description
The Kaggle dataset includes hourly bike rental data with the following features:

datetime: Hourly timestamp.
season: Categorical (1 = winter, 2 = spring, 3 = summer, 4 = fall).
holiday: Binary (1 = holiday, 0 = non-holiday).
workingday: Binary (1 = neither weekend nor holiday, 0 = otherwise).
weather: Categorical (1 = clear, 2 = mist, 3 = light rain/snow, 4 = heavy rain/snow).
temp: Actual temperature in Celsius.
atemp: "Feels-like" temperature in Celsius.
humidity: Relative humidity percentage.
windspeed: Wind speed.
casual: Number of casual users.
registered: Number of registered users.
count: Total rentals (target variable).

The training data spans multiple years, while the test data requires predictions for future timestamps.
Methodology
Data Preprocessing

Parsed datetime to extract features: hour, day, weekday, is_weekend, is_rush_hour.
Binned temp and humidity into categorical ranges.
Created lag features (e.g., temp_lag1) and polynomial features (e.g., temp_squared).
Applied one-hot encoding to categorical variables.
Aligned train and test datasets to ensure consistent features.
Log-transformed the target (count) using np.log1p to stabilize variance.

Model Training

Tested multiple models (Linear Regression, Random Forest, XGBoost, LightGBM, CatBoost).
Used GridSearchCV and RandomizedSearchCV for hyperparameter tuning.
Evaluated models using RMSLE on a time-aware validation set.
The best model (CatBoost with RandomizedSearchCV) achieved an RMSLE of 0.36312.

Visualization
Predictions were visualized using Matplotlib and Seaborn to analyze trends and distributions. Key plots include:

Line Plot: Shows predictions over time, highlighting daily/weekly cycles.
Scatter Plot: Displays individual predictions to identify outliers.
Rolling Average Plot: Smooths predictions over a 24-hour window to reveal trends.
Histogram: Shows the distribution of predicted counts with a kernel density estimate.

Code Example (Visualization)
Below is an example of the visualization code used for the CatBoost model predictions:
import matplotlib.pyplot as plt
import seaborn as sns

# Line plot of predictions over time
plt.figure(figsize=(14, 5))
sns.lineplot(data=submission, x='datetime', y='count')
plt.title('CatBoost Predictions Over Time')
plt.xlabel('Datetime')
plt.ylabel('Predicted Count')
plt.tight_layout()
plt.show()

# Scatter plot of predictions
plt.figure(figsize=(14, 5))
sns.scatterplot(data=submission, x='datetime', y='count', alpha=0.5, s=10)
plt.title('Predicted Rentals Scatter Over Time')
plt.xlabel('Datetime')
plt.ylabel('Predicted Count')
plt.tight_layout()
plt.show()

# Rolling average of predictions
submission['rolling_mean'] = submission['count'].rolling(window=24).mean()  # Rolling over 1 day if hourly
plt.figure(figsize=(14, 5))
sns.lineplot(data=submission, x='datetime', y='rolling_mean', label='24-hour Rolling Mean')
sns.lineplot(data=submission, x='datetime', y='count', alpha=0.3, label='Original')
plt.title('Rolling Average of Predicted Rentals')
plt.xlabel('Datetime')
plt.ylabel('Predicted Count')
plt.legend()
plt.tight_layout()
plt.show()

# Histogram of predicted counts
plt.figure(figsize=(10, 5))
sns.histplot(submission['count'], bins=30, kde=True, color='teal')
plt.title('Distribution of Predicted Counts')
plt.xlabel('Predicted Count')
plt.ylabel('Frequency')
plt.tight_layout()
plt.show()

# Save submission
submission.to_csv('submission_catboost_randomsearch.csv', index=False)
print("Submission saved as 'submission_catboost_randomsearch.csv'")

Setup and Requirements
To run the code in this repository, ensure you have the following dependencies installed:
pip install pandas numpy scikit-learn xgboost lightgbm catboost matplotlib seaborn

Prerequisites

Python 3.8 or higher
Access to the Kaggle dataset (available in datasets/ or downloadable from Kaggle)
Jupyter Notebook (optional, for interactive visualization)

Running the Code

Clone this repository:git clone <repository-url>


Navigate to the models/ folder and select the desired model script (e.g., catboost_randomsearch.py).
Ensure the datasets (train.csv, test.csv) are in the datasets/ folder.
Run the script:python models/catboost_randomsearch.py


The script will generate predictions and save them to the submissions/ folder (e.g., submission_catboost_randomsearch.csv).
Visualizations will be displayed if run in an interactive environment or saved if specified.

Leaderboard Ranking Note
The Kaggle Bike Sharing Demand competition ended three years ago, so new submissions are not reflected on the public leaderboard. Based on the final RMSLE score of 0.36312 achieved by the CatBoost model with RandomizedSearchCV, the performance would place this model between the 16th and 17th positions on the historical leaderboard, effectively ranking 17th among competitors. This ranking is estimated by comparing the achieved RMSLE to the scores published at the time of the competition's conclusion.
Troubleshooting
Common Issues

Missing Dependencies: Install required libraries using the pip command above.
Data Loading Errors: Ensure train.csv and test.csv are in the datasets/ folder and have the correct format.
Visualization Issues:
Plots not displaying: Use %matplotlib inline in Jupyter or save plots with plt.savefig('plot.png').
Missing data: Verify the submission DataFrame with submission.info() and ensure datetime is parsed correctly (pd.to_datetime(submission['datetime'])).
Slow rendering: Sample data for large datasets (submission.sample(1000)) or adjust plot parameters (e.g., alpha=0.5, s=10).



Example Fix for Visualization
import pandas as pd
submission['datetime'] = pd.to_datetime(submission['datetime'])
print(submission.isna().sum())
plt.figure(figsize=(14, 5))
sns.scatterplot(data=submission.sample(1000), x='datetime', y='count', alpha=0.5, s=10)
plt.show()

License
This project is licensed under the MIT License. See the LICENSE file for details.
Acknowledgments

Kaggle for providing the Bike Sharing Demand dataset and competition platform.
Libraries: Pandas, NumPy, Scikit-learn, XGBoost, LightGBM, CatBoost, Matplotlib, Seaborn.

